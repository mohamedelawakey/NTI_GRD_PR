# -*- coding: utf-8 -*-
"""NLp_PR_COMP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11xeRUvuRDEw5jWKykoGdTmbB8tEt9KA4

# **Librarys**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
import string
import pickle
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report

"""# **Text Cleaning**"""

AR_STOPWORDS = set([
    'في', 'من', 'على', 'عن', 'إلى', 'أن', 'إن', 'كان', 'ما', 'لم', 'لن', 'قد', 'هذا', 'هذه', 'هناك',
    'هو', 'هي', 'هم', 'نحن', 'كما', 'أو', 'ثم', 'لكن', 'بل', 'أيضاً', 'حتى', 'مع', 'كل', 'أكثر', 'أقل',
    'لقد', 'ولا', 'له', 'منه', 'فيه', 'بين', 'بعد', 'عند', 'إلي', 'بدون', 'أحد', 'أي', 'شيء', 'لي',
    'به', 'فهو', 'فهي', 'كانت', 'ليس', 'لان', 'إذا', 'مثل', 'ضمن', 'أصبح', 'ذلك', 'والتي', 'والذي',
    'وهو', 'وهي', 'الذي', 'التي', 'الذين', 'اللذين', 'اللتي', 'بهذا', 'بها', 'بهم', 'بأن', 'فإن',
    'كما', 'إذ', 'حيث', 'أين', 'منذ', 'إما', 'أثناء', 'بينما', 'لأن', 'كأن', 'إلا', 'قد', 'حتي',
    'أو', 'و', 'ب', 'ل', 'ف', 'س', 'ك', 'ي', 'ت', 'ن', 'ا', 'إنه', 'أنها', 'وإن', 'أن', 'إن', 'مازال',
    'مايزال', 'مافتئ', 'ماانفك', 'ما برح', 'لايزال', 'ليس', 'ما', 'لاتزال', 'لاتزال', 'لن', 'لم', 'لا'
])

def clean_arabic_text(text):
    text = str(text).lower()
    text = re.sub(r'^\s*\d+\s*\.*\s*', '', text)
    text = re.sub(r'\d+', '', text)
    text = re.sub(rf"[{re.escape(string.punctuation)}]", ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    words = text.split()
    words = [w for w in words if w not in AR_STOPWORDS and len(w) > 1]
    return ' '.join(words)

"""# **Reading Data & Preparation**"""

data = pd.read_csv('cleaned_data - cleaned_data(1).csv')
data

"""# **Data Spliting**"""

X = data['symptoms_text']
y = data['specialty']

counts = y.value_counts()
data = data[data['specialty'].isin(counts[counts >= 2].index)]

X = data['symptoms_text']
y = data['specialty']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""# **MODEL PIPELINE**"""

pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(ngram_range=(1, 2), token_pattern=r'\b\w+\b', max_features=5000)),
    ('clf', LogisticRegression(max_iter=1000))
])

"""# **Tranning**"""

pipeline.fit(X_train, y_train)

"""# **predict**"""

y_pred = pipeline.predict(X_test)
y_pred

"""# **Evaluation & Report**"""

print(classification_report(y_test, y_pred))

def predict_specialty(text):
    clean = clean_arabic_text(text)
    return pipeline.predict([clean])[0]

print(predict_specialty("عندي ألم في الصدر وسعال متكرر"))

"""# **Save Model**"""

with open('arabic_symptom_model.pkl', 'wb') as f:
    pickle.dump(pipeline, f)

print("✅ الموديل محفوظ باسم: arabic_symptom_model.pkl")





